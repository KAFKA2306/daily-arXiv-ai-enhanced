{"id": "2012.10055", "categories": ["eess.AS", "cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2012.10055", "abs": "https://arxiv.org/abs/2012.10055", "authors": ["Shota Horiguchi", "Paola Garcia", "Yusuke Fujita", "Shinji Watanabe", "Kenji Nagamatsu"], "title": "End-to-End Speaker Diarization as Post-Processing", "comment": null, "summary": "This paper investigates the utilization of an end-to-end diarization model as post-processing of conventional clustering-based diarization. Clustering-based diarization methods partition frames into clusters of the number of speakers; thus, they typically cannot handle overlapping speech because each frame is assigned to one speaker. On the other hand, some end-to-end diarization methods can handle overlapping speech by treating the problem as multi-label classification. Although some methods can treat a flexible number of speakers, they do not perform well when the number of speakers is large. To compensate for each other's weakness, we propose to use a two-speaker end-to-end diarization method as post-processing of the results obtained by a clustering-based method. We iteratively select two speakers from the results and update the results of the two speakers to improve the overlapped region. Experimental results show that the proposed algorithm consistently improved the performance of the state-of-the-art methods across CALLHOME, AMI, and DIHARD II datasets.", "AI": {"tldr": "\u5f93\u6765\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u624b\u6cd5\u306e\u7d50\u679c\u3092\u30012\u8a71\u8005\u5bfe\u5fdc\u306e\u30a8\u30f3\u30c9\u30c4\u30fc\u30a8\u30f3\u30c9\uff08E2E\uff09\u30c0\u30a4\u30a2\u30ea\u30bc\u30fc\u30b7\u30e7\u30f3\u30e2\u30c7\u30eb\u3067\u5f8c\u51e6\u7406\u3059\u308b\u3053\u3068\u3067\u3001\u91cd\u8907\u767a\u8a71\u533a\u9593\u306e\u7cbe\u5ea6\u3092\u5411\u4e0a\u3055\u305b\u3001\u6700\u5148\u7aef\u306e\u6027\u80fd\u3092\u4e00\u8cab\u3057\u3066\u6539\u5584\u3057\u305f\u3002", "motivation": "\u5f93\u6765\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30d9\u30fc\u30b9\u306e\u624b\u6cd5\u306f\u5404\u30d5\u30ec\u30fc\u30e0\u30921\u8a71\u8005\u306b\u3057\u304b\u5272\u308a\u5f53\u3066\u3089\u308c\u306a\u3044\u305f\u3081\u3001\u91cd\u8907\u767a\u8a71\u306b\u5bfe\u5fdc\u3067\u304d\u306a\u3044\u3002\u4e00\u65b9\u3001E2E\u624b\u6cd5\u306f\u91cd\u8907\u767a\u8a71\u306b\u5bfe\u5fdc\u3067\u304d\u308b\u3082\u306e\u306e\u3001\u8a71\u8005\u6570\u304c\u591a\u3044\u5834\u5408\u306b\u6027\u80fd\u304c\u4f4e\u4e0b\u3059\u308b\u3068\u3044\u3046\u3001\u4e92\u3044\u306e\u5f31\u70b9\u3092\u88dc\u5b8c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002", "method": "\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30d9\u30fc\u30b9\u306e\u30c0\u30a4\u30a2\u30ea\u30bc\u30fc\u30b7\u30e7\u30f3\u7d50\u679c\u306b\u5bfe\u3057\u3066\u30012\u8a71\u8005\u5bfe\u5fdc\u306e\u30a8\u30f3\u30c9\u30c4\u30fc\u30a8\u30f3\u30c9\uff08E2E\uff09\u30c0\u30a4\u30a2\u30ea\u30bc\u30fc\u30b7\u30e7\u30f3\u30e2\u30c7\u30eb\u3092\u5f8c\u51e6\u7406\u3068\u3057\u3066\u5229\u7528\u3059\u308b\u3002\u7d50\u679c\u304b\u30892\u8a71\u8005\u3092\u53cd\u5fa9\u7684\u306b\u9078\u629e\u3057\u3001E2E\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3066\u305d\u306e2\u8a71\u8005\u306e\u91cd\u8907\u533a\u9593\u3092\u66f4\u65b0\u30fb\u6539\u5584\u3059\u308b\u3002", "result": "\u63d0\u6848\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u306f\u3001CALLHOME\u3001AMI\u3001DIHARD II\u306e\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306b\u304a\u3044\u3066\u3001\u6700\u5148\u7aef\u306e\u624b\u6cd5\u306e\u6027\u80fd\u3092\u4e00\u8cab\u3057\u3066\u5411\u4e0a\u3055\u305b\u305f\u3002", "conclusion": "\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u30d9\u30fc\u30b9\u306e\u624b\u6cd5\u30682\u8a71\u8005E2E\u30e2\u30c7\u30eb\u3092\u7d44\u307f\u5408\u308f\u305b\u305f\u5f8c\u51e6\u7406\u30a2\u30d7\u30ed\u30fc\u30c1\u306f\u3001\u91cd\u8907\u767a\u8a71\u51e6\u7406\u306b\u304a\u3051\u308b\u5f93\u6765\u624b\u6cd5\u306e\u5f31\u70b9\u3092\u52b9\u679c\u7684\u306b\u88dc\u5b8c\u3057\u3001\u30ed\u30d0\u30b9\u30c8\u306a\u6027\u80fd\u6539\u5584\u3092\u9054\u6210\u3057\u305f\u3002"}}
{"id": "2012.10187", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2012.10187", "abs": "https://arxiv.org/abs/2012.10187", "authors": ["Tianyi Liu", "Xiangyu Lin", "Weijia Jia", "Mingliang Zhou", "Wei Zhao"], "title": "Regularized Attentive Capsule Network for Overlapped Relation Extraction", "comment": "11 pages, 7 figures", "summary": "Distantly supervised relation extraction has been widely applied in knowledge base construction due to its less requirement of human efforts. However, the automatically established training datasets in distant supervision contain low-quality instances with noisy words and overlapped relations, introducing great challenges to the accurate extraction of relations. To address this problem, we propose a novel Regularized Attentive Capsule Network (RA-CapNet) to better identify highly overlapped relations in each informal sentence. To discover multiple relation features in an instance, we embed multi-head attention into the capsule network as the low-level capsules, where the subtraction of two entities acts as a new form of relation query to select salient features regardless of their positions. To further discriminate overlapped relation features, we devise disagreement regularization to explicitly encourage the diversity among both multiple attention heads and low-level capsules. Extensive experiments conducted on widely used datasets show that our model achieves significant improvements in relation extraction.", "AI": {"tldr": "\u9060\u9694\u76e3\u8996\u95a2\u4fc2\u62bd\u51fa\u306e\u30ce\u30a4\u30ba\u3068\u91cd\u8907\u95a2\u4fc2\u306e\u554f\u984c\u3092\u89e3\u6c7a\u3059\u308b\u305f\u3081\u3001\u30de\u30eb\u30c1\u30d8\u30c3\u30c9\u6ce8\u610f\u3068\u30ab\u30d7\u30bb\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7d71\u5408\u3057\u3001\u3055\u3089\u306b\u4e0d\u4e00\u81f4\u6b63\u5247\u5316\u3092\u9069\u7528\u3057\u305f\u65b0\u3057\u3044\u30e2\u30c7\u30eb\u300cRA-CapNet\u300d\u3092\u63d0\u6848\u3002\u3053\u308c\u306b\u3088\u308a\u3001\u95a2\u4fc2\u62bd\u51fa\u306e\u7cbe\u5ea6\u304c\u5927\u5e45\u306b\u5411\u4e0a\u3057\u305f\u3002", "motivation": "\u9060\u9694\u76e3\u8996\u306b\u3088\u308b\u95a2\u4fc2\u62bd\u51fa\u306f\u77e5\u8b58\u30d9\u30fc\u30b9\u69cb\u7bc9\u306b\u5e83\u304f\u5fdc\u7528\u3055\u308c\u3066\u3044\u308b\u304c\u3001\u81ea\u52d5\u7684\u306b\u69cb\u7bc9\u3055\u308c\u308b\u8a13\u7df4\u30c7\u30fc\u30bf\u306b\u306f\u3001\u30ce\u30a4\u30ba\u306e\u591a\u3044\u5358\u8a9e\u3084\u95a2\u4fc2\u304c\u91cd\u8907\u3057\u305f\u4f4e\u54c1\u8cea\u306a\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u304c\u542b\u307e\u308c\u3066\u304a\u308a\u3001\u6b63\u78ba\u306a\u95a2\u4fc2\u62bd\u51fa\u306e\u5927\u304d\u306a\u8ab2\u984c\u3068\u306a\u3063\u3066\u3044\u308b\u3002", "method": "\u9ad8\u5ea6\u306b\u91cd\u8907\u3057\u305f\u95a2\u4fc2\u3092\u8b58\u5225\u3059\u308b\u305f\u3081\u3001Regularized Attentive Capsule Network (RA-CapNet)\u3092\u63d0\u6848\u3002\u4f4e\u30ec\u30d9\u30eb\u30ab\u30d7\u30bb\u30eb\u3068\u3057\u3066\u30de\u30eb\u30c1\u30d8\u30c3\u30c9\u6ce8\u610f\u6a5f\u69cb\u3092\u30ab\u30d7\u30bb\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306b\u7d44\u307f\u8fbc\u307f\u3001\u30a8\u30f3\u30c6\u30a3\u30c6\u30a3\u306e\u5f15\u304d\u7b97\u3092\u95a2\u4fc2\u30af\u30a8\u30ea\u3068\u3057\u3066\u5229\u7528\u3057\u3066\u9855\u8457\u306a\u7279\u5fb4\u3092\u9078\u629e\u3059\u308b\u3002\u3055\u3089\u306b\u3001\u91cd\u8907\u95a2\u4fc2\u7279\u5fb4\u306e\u8b58\u5225\u529b\u3092\u9ad8\u3081\u308b\u305f\u3081\u3001\u8907\u6570\u306e\u6ce8\u610f\u30d8\u30c3\u30c9\u3068\u4f4e\u30ec\u30d9\u30eb\u30ab\u30d7\u30bb\u30eb\u306e\u591a\u69d8\u6027\u3092\u660e\u793a\u7684\u306b\u4fc3\u3059\u300c\u4e0d\u4e00\u81f4\u6b63\u5247\u5316\u300d\u3092\u5c0e\u5165\u3057\u305f\u3002", "result": "\u5e83\u304f\u4f7f\u7528\u3055\u308c\u3066\u3044\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u5e83\u7bc4\u306a\u5b9f\u9a13\u3092\u884c\u3063\u305f\u7d50\u679c\u3001\u63d0\u6848\u30e2\u30c7\u30eb\u306f\u95a2\u4fc2\u62bd\u51fa\u306b\u304a\u3044\u3066\u8457\u3057\u3044\u6027\u80fd\u5411\u4e0a\u3092\u9054\u6210\u3057\u305f\u3002", "conclusion": "\u63d0\u6848\u3055\u308c\u305fRegularized Attentive Capsule Network (RA-CapNet)\u306f\u3001\u9060\u9694\u76e3\u8996\u306b\u304a\u3051\u308b\u30ce\u30a4\u30ba\u3084\u91cd\u8907\u3057\u305f\u95a2\u4fc2\u306e\u554f\u984c\u3092\u52b9\u679c\u7684\u306b\u89e3\u6c7a\u3057\u3001\u95a2\u4fc2\u62bd\u51fa\u306e\u6027\u80fd\u3092\u5927\u5e45\u306b\u5411\u4e0a\u3055\u305b\u308b\u3053\u3068\u3092\u793a\u3057\u305f\u3002"}}
{"id": "2012.10226", "categories": ["cs.IR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2012.10226", "abs": "https://arxiv.org/abs/2012.10226", "authors": ["Omkar Gurjar", "Manish Gupta"], "title": "Should I visit this place? Inclusion and Exclusion Phrase Mining from Reviews", "comment": "Accepted at European Conference On Information Retrieval (ECIR) 2021; 8 pages", "summary": "Although several automatic itinerary generation services have made travel planning easy, often times travellers find themselves in unique situations where they cannot make the best out of their trip. Visitors differ in terms of many factors such as suffering from a disability, being of a particular dietary preference, travelling with a toddler, etc. While most tourist spots are universal, others may not be inclusive for all. In this paper, we focus on the problem of mining inclusion and exclusion phrases associated with 11 such factors, from reviews related to a tourist spot. While existing work on tourism data mining mainly focuses on structured extraction of trip related information, personalized sentiment analysis, and automatic itinerary generation, to the best of our knowledge this is the first work on inclusion/exclusion phrase mining from tourism reviews. Using a dataset of 2000 reviews related to 1000 tourist spots, our broad level classifier provides a binary overlap F1 of $\\sim$80 and $\\sim$82 to classify a phrase as inclusion or exclusion respectively. Further, our inclusion/exclusion classifier provides an F1 of $\\sim$98 and $\\sim$97 for 11-class inclusion and exclusion classification respectively. We believe that our work can significantly improve the quality of an automatic itinerary generation service.", "AI": {"tldr": "\u89b3\u5149\u30ec\u30d3\u30e5\u30fc\u304b\u3089\u3001\u969c\u5bb3\u3084\u98df\u4e8b\u5236\u9650\u306a\u3069\u306e11\u306e\u7279\u5b9a\u306e\u8981\u56e0\u306b\u95a2\u9023\u3059\u308b\u65bd\u8a2d\u306e\u300c\u5305\u62ec\u6027\u300d\u304a\u3088\u3073\u300c\u6392\u4ed6\u6027\u300d\u3092\u793a\u3059\u30d5\u30ec\u30fc\u30ba\u3092\u81ea\u52d5\u62bd\u51fa\u3059\u308b\u624b\u6cd5\u3092\u63d0\u6848\u3002\u8a73\u7d30\u5206\u985e\u306b\u304a\u3044\u306697%\u4ee5\u4e0a\u306e\u9ad8\u3044F1\u30b9\u30b3\u30a2\u3092\u9054\u6210\u3057\u3001\u500b\u5225\u5316\u3055\u308c\u305f\u65c5\u884c\u8a08\u753b\u306e\u7cbe\u5ea6\u5411\u4e0a\u306b\u8ca2\u732e\u3059\u308b\u3002", "motivation": "\u5f93\u6765\u306e\u81ea\u52d5\u65c5\u884c\u8a08\u753b\u751f\u6210\u30b5\u30fc\u30d3\u30b9\u306f\u3001\u969c\u5bb3\u3084\u98df\u4e8b\u5236\u9650\u3001\u5e7c\u5150\u9023\u308c\u306a\u3069\u306e\u65c5\u884c\u8005\u306e\u500b\u5225\u7684\u304b\u3064\u56fa\u6709\u306e\u72b6\u6cc1\u306b\u5bfe\u5fdc\u3067\u304d\u3066\u304a\u3089\u305a\u3001\u3059\u3079\u3066\u306e\u89b3\u5149\u5730\u304c\u3059\u3079\u3066\u306e\u4eba\u306b\u5305\u62ec\u7684\u3067\u3042\u308b\u308f\u3051\u3067\u306f\u306a\u3044\u3068\u3044\u3046\u554f\u984c\u304c\u3042\u308b\u3002\u3053\u308c\u307e\u3067\u306e\u89b3\u5149\u30c7\u30fc\u30bf\u30de\u30a4\u30cb\u30f3\u30b0\u7814\u7a76\u3067\u306f\u3001\u30ec\u30d3\u30e5\u30fc\u304b\u3089\u5305\u62ec\u6027/\u6392\u4ed6\u6027\u30d5\u30ec\u30fc\u30ba\u3092\u30de\u30a4\u30cb\u30f3\u30b0\u3059\u308b\u53d6\u308a\u7d44\u307f\u304c\u4e0d\u8db3\u3057\u3066\u3044\u305f\u305f\u3081\u3001\u3053\u308c\u3092\u88dc\u5b8c\u3059\u308b\u3002", "method": "1000\u7b87\u6240\u306e\u89b3\u5149\u5730\u306b\u95a2\u9023\u3059\u308b2000\u4ef6\u306e\u30ec\u30d3\u30e5\u30fc\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u7528\u3057\u3001\u4e8c\u6bb5\u968e\u306e\u5206\u985e\u5668\u3092\u958b\u767a\u3057\u305f\u3002\u7b2c\u4e00\u306b\u3001\u30d5\u30ec\u30fc\u30ba\u3092\u300c\u5305\u62ec\uff08Inclusion\uff09\u300d\u307e\u305f\u306f\u300c\u6392\u4ed6\uff08Exclusion\uff09\u300d\u3068\u3057\u3066\u4e8c\u5024\u5206\u985e\u3059\u308b\u5e83\u57df\u5206\u985e\u5668\u3002\u7b2c\u4e8c\u306b\u300111\u7a2e\u985e\u306e\u7279\u5b9a\u306e\u8981\u56e0\u306b\u57fa\u3065\u3044\u3066\u5305\u62ec/\u6392\u4ed6\u3092\u5206\u985e\u3059\u308b11\u30af\u30e9\u30b9\u306e\u8a73\u7d30\u5206\u985e\u5668\u3002", "result": "\u5e83\u57df\u5206\u985e\u5668\uff08\u4e8c\u5024\u5206\u985e\uff09\u306f\u3001\u5305\u62ec\u5206\u985e\u3067\u7d0480\u3001\u6392\u4ed6\u5206\u985e\u3067\u7d0482\u306e\u30d0\u30a4\u30ca\u30ea\u30aa\u30fc\u30d0\u30fc\u30e9\u30c3\u30d7F1\u30b9\u30b3\u30a2\u3092\u9054\u6210\u3057\u305f\u3002\u3055\u3089\u306b\u3001\u8a73\u7d30\u5206\u985e\u5668\uff0811\u30af\u30e9\u30b9\u5206\u985e\uff09\u306f\u3001\u5305\u62ec\u5206\u985e\u3067\u7d0498\u3001\u6392\u4ed6\u5206\u985e\u3067\u7d0497\u3068\u3044\u3046\u9ad8\u3044F1\u30b9\u30b3\u30a2\u3092\u9054\u6210\u3057\u305f\u3002", "conclusion": "\u672c\u7814\u7a76\u3067\u63d0\u6848\u3055\u308c\u305f\u89b3\u5149\u30ec\u30d3\u30e5\u30fc\u304b\u3089\u306e\u5305\u62ec\u6027/\u6392\u4ed6\u6027\u30d5\u30ec\u30fc\u30ba\u306e\u30de\u30a4\u30cb\u30f3\u30b0\u306f\u3001\u81ea\u52d5\u65c5\u884c\u8a08\u753b\u751f\u6210\u30b5\u30fc\u30d3\u30b9\u306e\u8cea\u3092\u5927\u5e45\u306b\u6539\u5584\u3057\u3001\u65c5\u884c\u8005\u306e\u500b\u5225\u30cb\u30fc\u30ba\u306b\u5408\u308f\u305b\u305f\u3001\u3088\u308a\u8cea\u306e\u9ad8\u3044\u884c\u7a0b\u3092\u63d0\u4f9b\u3059\u308b\u53ef\u80fd\u6027\u3092\u79d8\u3081\u3066\u3044\u308b\u3002"}}
{"id": "2012.13004", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2012.13004", "abs": "https://arxiv.org/abs/2012.13004", "authors": ["Deblin Bagchi", "Shannon Wotherspoon", "Zhuolin Jiang", "Prasanna Muthukumar"], "title": "Speech Synthesis as Augmentation for Low-Resource ASR", "comment": null, "summary": "Speech synthesis might hold the key to low-resource speech recognition. Data augmentation techniques have become an essential part of modern speech recognition training. Yet, they are simple, naive, and rarely reflect real-world conditions. Meanwhile, speech synthesis techniques have been rapidly getting closer to the goal of achieving human-like speech. In this paper, we investigate the possibility of using synthesized speech as a form of data augmentation to lower the resources necessary to build a speech recognizer. We experiment with three different kinds of synthesizers: statistical parametric, neural, and adversarial. Our findings are interesting and point to new research directions for the future.", "AI": {"tldr": "\u4f4e\u30ea\u30bd\u30fc\u30b9\u74b0\u5883\u3067\u306e\u97f3\u58f0\u8a8d\u8b58\uff08ASR\uff09\u306e\u6539\u5584\u3092\u76ee\u6307\u3057\u3001\u7d71\u8a08\u7684\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u3001\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u542b\u30803\u7a2e\u985e\u306e\u9ad8\u5ea6\u306a\u5408\u6210\u97f3\u58f0\u3092\u7528\u3044\u305f\u30c7\u30fc\u30bf\u62e1\u5f35\u306e\u6709\u52b9\u6027\u3092\u8abf\u67fb\u3057\u305f\u3002", "motivation": "\u65e2\u5b58\u306e\u30c7\u30fc\u30bf\u62e1\u5f35\u624b\u6cd5\u306f\u5358\u7d14\u3067\u73fe\u5b9f\u4e16\u754c\u306e\u72b6\u6cc1\u3092\u53cd\u6620\u3057\u3066\u3044\u306a\u3044\u3002\u4e00\u65b9\u3001\u97f3\u58f0\u5408\u6210\u6280\u8853\u306f\u4eba\u9593\u306e\u3088\u3046\u306a\u97f3\u58f0\u3092\u5b9f\u73fe\u3059\u308b\u30ec\u30d9\u30eb\u306b\u6025\u901f\u306b\u8fd1\u3065\u3044\u3066\u304a\u308a\u3001\u3053\u308c\u3092\u6d3b\u7528\u3057\u3066\u97f3\u58f0\u8a8d\u8b58\u306b\u5fc5\u8981\u306a\u30ea\u30bd\u30fc\u30b9\u3092\u524a\u6e1b\u3059\u308b\u3053\u3068\u304c\u52d5\u6a5f\u3002", "method": "\u5408\u6210\u97f3\u58f0\u3092\u30c7\u30fc\u30bf\u62e1\u5f35\u3068\u3057\u3066\u5229\u7528\u3057\u3001\u97f3\u58f0\u8a8d\u8b58\u30e2\u30c7\u30eb\u306e\u30c8\u30ec\u30fc\u30cb\u30f3\u30b0\u306b\u9069\u7528\u3057\u305f\u3002\u5b9f\u9a13\u3067\u306f\u3001\u7d71\u8a08\u7684\u30d1\u30e9\u30e1\u30c8\u30ea\u30c3\u30af\u3001\u30cb\u30e5\u30fc\u30e9\u30eb\u3001\u6575\u5bfe\u7684\u751f\u6210\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\uff08Adversarial\uff09\u306e3\u7a2e\u985e\u306e\u5408\u6210\u5668\u3092\u6bd4\u8f03\u691c\u8a0e\u3057\u305f\u3002", "result": "\u672c\u7814\u7a76\u306e\u767a\u898b\u306f\u8208\u5473\u6df1\u304f\u3001\u5c06\u6765\u306e\u65b0\u305f\u306a\u7814\u7a76\u65b9\u5411\u6027\u3092\u793a\u5506\u3059\u308b\u3082\u306e\u3067\u3042\u3063\u305f\u3002", "conclusion": "\u97f3\u58f0\u5408\u6210\u306f\u3001\u9ad8\u5ea6\u306a\u30c7\u30fc\u30bf\u62e1\u5f35\u6280\u8853\u3068\u3057\u3066\u6a5f\u80fd\u3057\u3001\u4f4e\u30ea\u30bd\u30fc\u30b9\u97f3\u58f0\u8a8d\u8b58\u306e\u9375\u3092\u63e1\u308b\u53ef\u80fd\u6027\u304c\u3042\u308b\u3002"}}
{"id": "2012.13190", "categories": ["cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2012.13190", "abs": "https://arxiv.org/abs/2012.13190", "authors": ["Yves Rychener", "Xavier Renard", "Djam\u00e9 Seddah", "Pascal Frossard", "Marcin Detyniecki"], "title": "QUACKIE: A NLP Classification Task With Ground Truth Explanations", "comment": null, "summary": "NLP Interpretability aims to increase trust in model predictions. This makes evaluating interpretability approaches a pressing issue. There are multiple datasets for evaluating NLP Interpretability, but their dependence on human provided ground truths raises questions about their unbiasedness. In this work, we take a different approach and formulate a specific classification task by diverting question-answering datasets. For this custom classification task, the interpretability ground-truth arises directly from the definition of the classification problem. We use this method to propose a benchmark and lay the groundwork for future research in NLP interpretability by evaluating a wide range of current state of the art methods.", "AI": {"tldr": "NLP\u89e3\u91c8\u6027\u306e\u8a55\u4fa1\u306b\u304a\u3051\u308b\u4eba\u9593\u306e\u30d0\u30a4\u30a2\u30b9\u3092\u6392\u9664\u3059\u308b\u305f\u3081\u3001QA\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8ee2\u7528\u3057\u305f\u30ab\u30b9\u30bf\u30e0\u5206\u985e\u30bf\u30b9\u30af\u3092\u63d0\u6848\u3057\u3001\u305d\u306e\u554f\u984c\u5b9a\u7fa9\u304b\u3089\u76f4\u63a5\u5c0e\u304b\u308c\u308b\u771f\u5024\u3092\u7528\u3044\u3066\u3001\u65b0\u3057\u3044\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u69cb\u7bc9\u3057\u305f\u3002", "motivation": "NLP\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u306b\u5bfe\u3059\u308b\u4fe1\u983c\u6027\u3092\u9ad8\u3081\u308b\u305f\u3081\u306b\u89e3\u91c8\u6027\u8a55\u4fa1\u304c\u91cd\u8981\u3060\u304c\u3001\u65e2\u5b58\u306e\u8a55\u4fa1\u7528\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306f\u4eba\u9593\u306e\u63d0\u4f9b\u3059\u308b\u771f\u5024\u306b\u4f9d\u5b58\u3057\u3066\u304a\u308a\u3001\u305d\u306e\u30d0\u30a4\u30a2\u30b9\u304c\u61f8\u5ff5\u3055\u308c\u308b\u305f\u3081\u3002", "method": "\u65e2\u5b58\u306e\u8cea\u554f\u5fdc\u7b54\uff08QA\uff09\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u8ee2\u7528\u3057\u3001\u7279\u5b9a\u306e\u30ab\u30b9\u30bf\u30e0\u5206\u985e\u30bf\u30b9\u30af\u3092\u5b9a\u5f0f\u5316\u3059\u308b\u3002\u3053\u306e\u30ab\u30b9\u30bf\u30e0\u5206\u985e\u30bf\u30b9\u30af\u306e\u5b9a\u7fa9\u81ea\u4f53\u304b\u3089\u3001\u89e3\u91c8\u6027\u306e\u771f\u5024\uff08\u30b0\u30e9\u30a6\u30f3\u30c9\u30fb\u30c8\u30a5\u30eb\u30fc\u30b9\uff09\u304c\u76f4\u63a5\u5c0e\u304d\u51fa\u3055\u308c\u308b\u3088\u3046\u306b\u8a2d\u8a08\u3059\u308b\u3002", "result": "\u3053\u306e\u624b\u6cd5\u3092\u7528\u3044\u3066\u65b0\u3057\u3044\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u63d0\u6848\u3057\u3001\u5e45\u5e83\u3044\u6700\u5148\u7aef\u306e\u89e3\u91c8\u6027\u8a55\u4fa1\u624b\u6cd5\u3092\u3053\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u4e0a\u3067\u8a55\u4fa1\u3057\u305f\u3002", "conclusion": "\u4eba\u9593\u306b\u3088\u308b\u30d0\u30a4\u30a2\u30b9\u3092\u6392\u9664\u3057\u305f\u89e3\u91c8\u6027\u8a55\u4fa1\u306e\u305f\u3081\u306e\u65b0\u3057\u3044\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u3092\u63d0\u4f9b\u3057\u3001\u4eca\u5f8c\u306eNLP\u89e3\u91c8\u6027\u7814\u7a76\u306e\u57fa\u76e4\u3092\u7bc9\u3044\u305f\u3002"}}
